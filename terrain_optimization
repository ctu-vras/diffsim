#! /usr/bin/env python

import torch
import warp as wp
import numpy as np
import os
from tqdm import tqdm
from diffsim.src.utils import read_yaml
from src.datasets.robingas import compile_data
from src.models.DiffSim import DiffSim
from src.models.TerrainEncoder import compile_model
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import DataLoader
from datetime import datetime

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
wp.init()  # init warp!


def get_gt_trajectories(batch_size):
    def pose2mat(pose):
        T = np.eye(4)
        T[:3, :4] = pose.reshape((3, 4))
        return T

    def id2stamp(id):
        sec, nsec = id.split('_')
        assert len(sec) == 10, 'seconds should have 10 digits'
        assert len(nsec) == 9, 'nanoseconds should have 9 digits'
        sec = float(sec)
        nsec = float(nsec)
        return sec + nsec * 1e-9

    # define target poses with timestamps for each robot
    num_poses = 30
    T_horizon = 5000
    poses0 = np.zeros((num_poses, 7))
    poses0[:, 6] = 1  # quaternion w
    poses0[:, 0] = np.arange(num_poses) / num_poses * 1  # x coordinate
    poses0[:, 2] = 1.0
    timesteps0 = (T_horizon * np.arange(num_poses) / num_poses).astype(int)
    poses_list = [poses0[:] for _ in range(batch_size)]
    timestamps_list = [timesteps0[:] for _ in range(batch_size)]

    # data = np.loadtxt(poses_path, delimiter=',', skiprows=1)
    # all_timestamps, Ts = data[:, 0], data[:, 1:13]
    # lidar_poses = np.asarray([pose2mat(pose) for pose in Ts], dtype=np.float32)
    # # poses of the robot in the map frame
    # Tr_robot_lidar = calib['transformations']['T_base_link__os_sensor']['data']
    # Tr_robot_lidar = np.asarray(Tr_robot_lidar, dtype=np.float32).reshape((4, 4))
    # Tr_lidar_robot = np.linalg.inv(Tr_robot_lidar)
    # all_poses = lidar_poses @ Tr_lidar_robot
    #
    # poses_list = []
    # timestamps_list = []
    # for id in ids:
    #     stamp = id2stamp(id)
    #     il = np.argmin(np.abs(all_timestamps - stamp))
    #     ir = np.clip(il + n_frames, 0, len(all_timestamps))
    #     poses = all_poses[il:ir]
    #     timestamps = np.asarray(all_timestamps[il:ir])
    #     assert len(poses) > 0, f'No poses found for trajectory {id}'
    #     poses = np.linalg.inv(poses[0]) @ poses
    #     timestamps -= timestamps[0]
    #
    #     # turn poses into quaternions
    #     xyz = poses[:, :3, 3]
    #     quats = np.asarray([Rotation.from_matrix(pose[:3, :3]).as_quat() for pose in poses], dtype=np.float32)
    #     poses = np.concatenate([xyz, quats], axis=1)
    #     timestamps_ms = timestamps * 1e3
    #
    #     poses_list.append(poses)
    #     timestamps_list.append(timestamps_ms.astype(int))

    return timestamps_list, poses_list

def get_control_inputs(batch_size, T_horizon):
    # define control input for each robot
    controls0 = 0.2 * np.ones((T_horizon, batch_size, 2))
    flipper_angles0 = np.zeros((T_horizon, batch_size, 4))
    controls = [controls0[:] for _ in range(batch_size)]
    flipper_angles = [flipper_angles0[:] for _ in range(batch_size)]

    return controls, flipper_angles


class Learner:
    def __init__(self, batch_size, lr=1e-3, weight_decay=1e-7,
                 robot='tradr', device='cpu', use_renderer=False):
        self.device = device
        self.use_cuda_graph = True if device == 'cuda' else False
        self.use_renderer = use_renderer
        self.batch_size = batch_size

        self.terrain_encoder_cfg = read_yaml(f'config/lss_cfg_{robot}.yaml')
        self.terrain_encoder_weights = f'config/weights/lss_robingas_{robot}.pt'
        self.terrain_encoder = self.init_terrain_encoder(self.terrain_encoder_cfg, weights=self.terrain_encoder_weights)

        self.dphys = self.init_diff_physics()

        self.geom_hm_loss_fn = torch.nn.MSELoss(reduction='none')
        self.optimizer = torch.optim.Adam(self.terrain_encoder.parameters(), lr=lr, weight_decay=weight_decay)

        self.data_loader = self.init_dataloader(batch_size=batch_size)

        log_dir = f'config/tb_runs/{datetime.now().strftime("%Y_%m_%d_%H_%M_%S")}'
        self.tb_writer = SummaryWriter(log_dir=log_dir)
        self.counter = 0

    def init_dataloader(self, batch_size=1):
        ds = compile_data(seq_i=1, robot='tradr', small=False)
        print('Dataset size:', len(ds))
        data_loader = DataLoader(ds, batch_size=batch_size, shuffle=False)
        return data_loader

    def init_terrain_encoder(self, terrain_encoder_cfg, weights=None):
        terrain_encoder = compile_model(terrain_encoder_cfg['grid_conf'], terrain_encoder_cfg['data_aug_conf'])
        if weights is not None and os.path.exists(weights):
            print(f'Loading pretrained LSS weights from {weights}')
            terrain_encoder.load_state_dict(torch.load(weights, map_location=self.device))
        terrain_encoder.to(self.device)
        terrain_encoder.train()
        return terrain_encoder

    def init_diff_physics(self):
        torch_hms, res = self.get_initial_heightmaps(self.batch_size)
        dphys = DiffSim(torch_hms, res, use_renderer=self.use_renderer, device=self.device)
        return dphys

    def get_initial_heightmaps(self, batch_size):
        xbound = self.terrain_encoder_cfg['grid_conf']['xbound']
        ybound = self.terrain_encoder_cfg['grid_conf']['ybound']
        grid_res = xbound[2]
        shp = (int((xbound[1] - xbound[0]) / grid_res), int((ybound[1] - ybound[0]) / grid_res))
        torch_hms = [torch.zeros(shp, dtype=torch.float32, device=self.device, requires_grad=True)
                     for _ in range(batch_size)]
        res = [grid_res for _ in range(batch_size)]  # heightmap resolutions
        return torch_hms, res

    def geom_hm_loss(self, height_pred, height_gt, weights=None):
        assert height_pred.shape == height_gt.shape, 'Height prediction and ground truth must have the same shape'
        if weights is None:
            weights = torch.ones_like(height_gt)
        assert weights.shape == height_gt.shape, 'Weights and height ground truth must have the same shape'

        # handle imbalanced height distribution (increase weights for higher heights / obstacles)
        h_mean = height_gt[weights.bool()].mean()
        # the higher the difference from mean the higher the weight
        weights_h = 1.0 + torch.abs(height_gt - h_mean)
        # apply height difference weights
        weights = weights * weights_h

        # compute weighted loss
        loss = (self.geom_hm_loss_fn(height_pred * weights, height_gt * weights)).mean()
        return loss

    def step(self, batch):
        self.dphys.init_shoot_states()  # load initial states for the shooter

        batch = [torch.as_tensor(b, dtype=torch.float32, device=self.device) for b in batch]
        img, rot, tran, intrins, post_rots, post_trans, hm_geom, hm_terrain = batch
        imgs_data = [img, rot, tran, intrins, post_rots, post_trans]

        # predict heightmaps
        height_pred = self.terrain_encoder(*imgs_data).squeeze(1)
        # dphysics trajectory loss
        _, loss_traj = self.dphys.simulate_and_backward_torch_tensor(height_pred, use_graph=self.use_cuda_graph)
        loss_traj = wp.to_torch(loss_traj)
        print('loss_traj: ', loss_traj)
        self.tb_writer.add_scalar('loss_traj', loss_traj, self.counter)

        # geometry heightmap loss
        loss_geom = self.geom_hm_loss(height_gt=hm_geom[:, 0], height_pred=height_pred, weights=hm_geom[:, 1])
        print('loss_geom: ', loss_geom)
        self.tb_writer.add_scalar('loss_geom', loss_geom, self.counter)

        loss = loss_geom + loss_traj
        print('loss: ', loss.item())
        self.tb_writer.add_scalar('loss', loss, self.counter)

        height_pred.backward(height_pred.grad, retain_graph=True)
        loss_geom.backward(retain_graph=True)

        self.optimizer.step()
        # necessary, since tape.zero() does not reach the torch tensor for some reason
        self.optimizer.zero_grad(set_to_none=False)

        if self.use_renderer and self.counter % 20 == 0:
            self.dphys.save_shoot_init_vels()  # save states for shooter
            self.dphys.simulate_single()  # simulate a single long trajectory for testing
            self.dphys.render_states('current', color=(1.0, 0.0, 0.0))
            self.dphys.render_simulation(pause=False)

        # update counter
        self.counter += 1

    def learn(self):
        # get ground-truth trajectory
        timestamps_ms, poses = get_gt_trajectories(self.batch_size)
        T_horizon_ms = int(timestamps_ms[0][-1])
        T_segment_ms = 300
        print('T_horizon_ms: ', T_horizon_ms)

        # get control inputs
        controls, flipper_angles = get_control_inputs(self.batch_size, T_horizon_ms)

        self.dphys.set_T(T_horizon_ms, T_segment_ms)
        self.dphys.set_target_poses(timestamps_ms, poses)
        self.dphys.set_control(controls, flipper_angles)

        if self.use_renderer:
            self.dphys.render_heightmaps()
            self.dphys.render_traj(poses[0][:, :3])

        # for batch in tqdm(self.data_loader, total=len(self.data_loader)):
        batch = next(iter(self.data_loader))
        for _ in range(100):
            self.step(batch)


def main():
    device = "cuda"
    use_renderer = True
    batch_size = 1
    robot = 'tradr'

    learner = Learner(batch_size=batch_size,
                      robot=robot,
                      device=device,
                      use_renderer=use_renderer)
    learner.learn()


if __name__ == '__main__':
    main()
